import time
import random
import re
from typing import List, Set, Optional
import requests
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st
import plotly.express as px

# KoNLPy ì„í¬íŠ¸ ì‹œë„
try:
    from konlpy.tag import Okt
except ImportError:
    st.error("KoNLPyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
except Exception as e:
    # Java ë¯¸ì„¤ì¹˜ ë“± ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œí•˜ê³  ì§„í–‰ (í˜•íƒœì†Œ ë¶„ì„ë§Œ ì•ˆë¨)
    pass

# -----------------------------
# 1. ì„¤ì • ë° í† í¬ë‚˜ì´ì €
# -----------------------------

DEFAULT_STOPWORDS: Set[str] = {
    "ê·¸ëƒ¥", "ê·¼ë°", "ê·¸ë¦¬ê³ ", "ë˜", "ì¢€", "ì´ê±°", "ì €ê±°", "ê±°ì˜",
    "ì§€ê¸ˆ", "ì˜¤ëŠ˜", "ë‚´ì¼", "ì–´ì œ", "ê·¸ëŸ¼", "ì œë°œ", "ì§„ì§œ", "ì¡´ë‚˜", 
    "ì‹œë°œ", "ë³‘ì‹ ", "í˜•ë“¤", "í˜•ë‹˜", "ê°œì¶”", "ë¹„ì¶”", "ì •ë„", "ë•Œë¬¸", 
    "ì‚¬ëŒ", "ìƒê°", "ë¬´ìŠ¨", "ì–´ë–»ê²Œ", "ì™œ", "ë‹¤ì‹œ", "ê³„ì†", "ë‚˜", "ë„ˆ", "ìš°ë¦¬",
    "í•˜ë‚˜", "ì§€ê¸ˆ", "ë³´ê³ ", "ê°€ì§€", "ë‹¬ëŸ¬", "ì£¼ì‹", "ì‹œì¥", "ë§¤ìˆ˜", "ë§¤ë„"
}

@st.cache_resource
def get_tokenizer():
    try:
        return Okt()
    except:
        return None

def tokenize_text_korean(text: str, stopwords: Optional[Set[str]] = None, min_len: int = 2) -> List[str]:
    if not isinstance(text, str):
        return []
    stopwords = stopwords or set()
    cleaned_text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", " ", text)
    
    okt = get_tokenizer()
    if okt:
        try:
            nouns = okt.nouns(cleaned_text)
        except:
            nouns = cleaned_text.split()
    else:
        nouns = cleaned_text.split()

    final_tokens = []
    for n in nouns:
        if len(n) >= min_len and n not in stopwords:
            final_tokens.append(n)
    return final_tokens

# -----------------------------
# 2. ê°•ë ¥í•´ì§„ í¬ë¡¤ëŸ¬ (V3)
# -----------------------------

def crawl_dc_v3(
    gallery_id: str,
    gallery_type: str, # 'minor', 'major', 'mini'
    start_page: int,
    end_page: int,
) -> pd.DataFrame:
    
    # ê°¤ëŸ¬ë¦¬ íƒ€ì…ì— ë”°ë¥¸ URL êµ¬ì¡° ë³€ê²½
    base_url = "https://gall.dcinside.com"
    if gallery_type == "minor":
        list_base = f"{base_url}/mgallery/board/lists/"
        view_base = f"{base_url}/mgallery/board/view/"
    elif gallery_type == "mini":
        list_base = f"{base_url}/mini/board/lists/"
        view_base = f"{base_url}/mini/board/view/"
    else: # major (ì •ì‹ ê°¤ëŸ¬ë¦¬)
        list_base = f"{base_url}/board/lists/"
        view_base = f"{base_url}/board/view/"

    # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ í—¤ë” ë³´ê°•
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://gall.dcinside.com/",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7"
    }

    rows = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_pages = end_page - start_page + 1
    
    # ì„¸ì…˜ ì‚¬ìš© (ì¿ í‚¤ ìœ ì§€)
    session = requests.Session()
    session.headers.update(headers)

    for idx, page in enumerate(range(start_page, end_page + 1)):
        status_text.text(f"ğŸ” {page}í˜ì´ì§€ ìŠ¤ìº” ì¤‘... (ê°¤ëŸ¬ë¦¬: {gallery_id})")
        progress_bar.progress((idx) / total_pages)
        
        # ëª©ë¡ ìš”ì²­
        params = {'id': gallery_id, 'page': page}
        try:
            res = session.get(list_base, params=params, timeout=10)
            if res.status_code != 200:
                st.warning(f"{page}í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨ (Code: {res.status_code})")
                continue
        except Exception as e:
            st.error(f"ì—°ê²° ì˜¤ë¥˜: {e}")
            continue

        soup = BeautifulSoup(res.text, "html.parser")
        
        # ê²Œì‹œê¸€ ëª©ë¡ ì°¾ê¸° (selectorê°€ ê°¤ëŸ¬ë¦¬ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ì—¬ëŸ¬ ê°œ ì‹œë„)
        trs = soup.select("tr.ub-content.us-post") 
        if not trs:
            trs = soup.select("tr.ub-content") # ì¼ë°˜ì ì¸ ê²½ìš°

        if not trs:
            # trì´ ì—†ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ê°€ ë‹¤ë¥¸ ê²ƒ (ë˜ëŠ” ì°¨ë‹¨ë¨)
            if "ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤" in res.text:
                st.info(f"{page}í˜ì´ì§€ì— ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            elif "location.replace" in res.text:
                st.error("ğŸš¨ ë””ì‹œì¸ì‚¬ì´ë“œ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                break
            continue

        for tr in trs:
            # ê³µì§€ì‚¬í•­ í•„í„°ë§ (ì„ íƒ ì‚¬í•­)
            if "ê³µì§€" in tr.get_text():
                continue

            a_tag = tr.select_one("a.ub-word")
            if not a_tag:
                continue

            title = a_tag.get_text(strip=True)
            link_href = a_tag.get("href")
            
            # ë§í¬ì—ì„œ ê¸€ ë²ˆí˜¸(no) ì¶”ì¶œí•˜ì—¬ ìƒì„¸ ì£¼ì†Œ ìƒì„±
            # href ì˜ˆ: /mgallery/board/view/?id=stockus&no=1234&page=1
            if not link_href: 
                continue
                
            match = re.search(r'no=([0-9]+)', link_href)
            if match:
                post_no = match.group(1)
                post_url = f"{view_base}?id={gallery_id}&no={post_no}"
            else:
                continue

            # ë‚ ì§œ
            date_td = tr.select_one("td.gall_date")
            timestamp_str = date_td.get("title") or date_td.get_text(strip=True) if date_td else ""

            # ë³¸ë¬¸ ìˆ˜ì§‘ (ì†ë„ ìœ„í•´ 0.3~1.0ì´ˆ ë”œë ˆì´)
            content_text = ""
            try:
                time.sleep(random.uniform(0.3, 0.8))
                pres = session.get(post_url, timeout=5)
                if pres.status_code == 200:
                    psoup = BeautifulSoup(pres.text, "html.parser")
                    content_div = psoup.select_one("div.write_div")
                    if content_div:
                        content_text = content_div.get_text(separator=" ", strip=True)
            except:
                pass

            rows.append({
                "timestamp_str": timestamp_str,
                "title": title,
                "content": content_text,
                "url": post_url
            })

    progress_bar.progress(1.0)
    status_text.text("ìˆ˜ì§‘ ì¢…ë£Œ")

    if not rows:
        return pd.DataFrame()

    df = pd.DataFrame(rows)
    
    # ë‚ ì§œ íŒŒì‹±
    def parse_date(x):
        x = str(x).strip()
        # ì˜¤ëŠ˜ ë‚ ì§œëŠ” 14:30 ì²˜ëŸ¼ ì‹œê°„ë§Œ ë‚˜ì˜´ -> ì˜¤ëŠ˜ ë‚ ì§œ ë¶™ì—¬ì¤Œ
        if re.match(r"\d{2}:\d{2}", x):
            today = datetime.datetime.now().strftime("%Y-%m-%d")
            return pd.to_datetime(f"{today} {x}")
        
        for fmt in ["%Y.%m.%d %H:%M:%S", "%Y.%m.%d %H:%M", "%Y-%m-%d"]:
            try:
                return pd.to_datetime(x, format=fmt)
            except:
                continue
        return pd.NaT

    import datetime
    df["timestamp"] = df["timestamp_str"].apply(parse_date)
    df = df.dropna(subset=["timestamp"])
    df["date"] = df["timestamp"].dt.date
    
    return df

# -----------------------------
# 3. í†µê³„ ë° ë©”ì¸ UI
# -----------------------------

def build_stats_v3(df_posts: pd.DataFrame):
    all_rows = []
    
    # ì§„í–‰ë°”
    prog = st.progress(0)
    total = len(df_posts)
    
    for i, row in df_posts.iterrows():
        if i % 5 == 0: prog.progress(min(i/total, 1.0))
        text = str(row["title"]) + " " + str(row["content"])
        tokens = tokenize_text_korean(text, stopwords=DEFAULT_STOPWORDS)
        for t in tokens:
            all_rows.append({"date": row["date"], "word": t})
            
    prog.progress(1.0)
    
    if not all_rows: return pd.DataFrame()
    
    df_t = pd.DataFrame(all_rows)
    df_daily = df_t.groupby(["date", "word"]).size().reset_index(name="count")
    
    daily_total = df_t.groupby("date").size().reset_index(name="total_words")
    df_daily = df_daily.merge(daily_total, on="date")
    df_daily["freq"] = df_daily["count"] / df_daily["total_words"]
    
    return df_daily

def main():
    st.set_page_config(page_title="ì£¼ì‹ ì‹¬ë¦¬ ë¶„ì„ê¸° V3", layout="wide")
    st.title("ğŸ“Š ë””ì”¨ ê°¤ëŸ¬ë¦¬ ë¶„ì„ê¸° V3")
    st.caption("ê°¤ëŸ¬ë¦¬ íƒ€ì… ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€ë¡œ ìˆ˜ì§‘ ì˜¤ë¥˜ í•´ê²°")

    if "df_daily" not in st.session_state: st.session_state["df_daily"] = pd.DataFrame()
    if "df_posts" not in st.session_state: st.session_state["df_posts"] = pd.DataFrame()

    with st.sidebar:
        st.header("1. ìˆ˜ì§‘ ì„¤ì •")
        
        # ê°¤ëŸ¬ë¦¬ ID
        gal_id = st.text_input("ê°¤ëŸ¬ë¦¬ ID", value="stockus")
        
        # âš ï¸ ì—¬ê¸°ê°€ í•µì‹¬: ê°¤ëŸ¬ë¦¬ íƒ€ì… ì„ íƒ
        gal_type = st.radio("ê°¤ëŸ¬ë¦¬ ì¢…ë¥˜ (ì¤‘ìš”)", 
                            ["minor", "major", "mini"], 
                            index=0,
                            format_func=lambda x: "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬" if x=="minor" else ("ì •ì‹ ê°¤ëŸ¬ë¦¬" if x=="major" else "ë¯¸ë‹ˆ ê°¤ëŸ¬ë¦¬"))
        st.info("â€» 'ë¯¸ì£¼ê°¤'ì€ ë§ˆì´ë„ˆ, 'ì½”ìŠ¤í”¼/ë¹„íŠ¸ì½”ì¸'ì€ ì •ì‹ì…ë‹ˆë‹¤.")

        c1, c2 = st.columns(2)
        sp = c1.number_input("ì‹œì‘ í˜ì´ì§€", 1, 1000, 1)
        ep = c2.number_input("ë í˜ì´ì§€", 1, 1000, 3)

        if st.button("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘"):
            with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
                df = crawl_dc_v3(gal_id, gal_type, sp, ep)
            
            if df.empty:
                st.error("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤! ê°¤ëŸ¬ë¦¬ IDë‚˜ ì¢…ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            else:
                st.success(f"{len(df)}ê°œ ê¸€ ìˆ˜ì§‘ ì„±ê³µ!")
                st.session_state["df_posts"] = df
                
                with st.spinner("ë‹¨ì–´ ë¶„ì„ ì¤‘..."):
                    stats = build_stats_v3(df)
                    st.session_state["df_daily"] = stats

    # ë©”ì¸ í™”ë©´
    df_d = st.session_state["df_daily"]
    
    if not df_d.empty:
        tab1, tab2 = st.tabs(["íŠ¸ë Œë“œ ì°¨íŠ¸", "ì›ë³¸ ë°ì´í„°"])
        
        with tab1:
            words = sorted(df_d["word"].unique())
            picks = st.multiselect("ì¶”ì í•  ë‹¨ì–´", words, default=words[:5] if len(words)>5 else words)
            
            if picks:
                sub = df_d[df_d["word"].isin(picks)].sort_values("date")
                fig = px.line(sub, x="date", y="count", color="word", markers=True)
                st.plotly_chart(fig, use_container_width=True)
                
        with tab2:
            st.dataframe(st.session_state["df_posts"])
    else:
        st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ìˆ˜ì§‘ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()